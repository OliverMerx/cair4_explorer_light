"""
================================
ğŸ’¡ CAIR4 Feed Forward Chat mit Datei-Upload
================================

ğŸš€ **Was ist der Feed Forward Chat mit Datei-Upload?**  
Dieser CAIR4 Use Case erweitert den klassischen **Feed Forward Chat** um eine **Datei-Upload-Funktion**, 
wodurch **Textdateien und PDFs** direkt in das KI-System eingespeist werden kÃ¶nnen.  
Damit wird das KI-System in die Lage versetzt, Fragen **auf Basis hochgeladener Inhalte** zu beantworten.  

WÃ¤hrend **klassische Chatbots** oft auf vorherige Nachrichten Bezug nehmen, bleibt der **Feed Forward Chat** 
bewusst **kontextfrei** â€“ jede Eingabe wird **unabhÃ¤ngig** verarbeitet.  
Durch die neue **Datei-Upload-Funktion** wird jedoch eine **einmalige Kontextanreicherung** fÃ¼r die aktuelle 
Anfrage ermÃ¶glicht.


Hier ist die Ã¼berarbeitete Einleitung, die noch klarer beschreibt, wo der Unterschied zur klassischen RAG-Variante liegt und was diese LÃ¶sung eigentlich macht. Die zentrale Botschaft: Hier wird nur einmalig Kontext durch ein hochgeladenes Dokument hinzugefÃ¼gt â€“ keine langfristige Speicherung, kein permanentes Retrieval. ğŸ¯

â¸»

ğŸ“Œ CAIR4 Feed Forward Chat mit Datei-Upload

Dieses Modul stellt eine einfache Variante eines Feed-Forward-Chats dar, der zusÃ¤tzlich die MÃ¶glichkeit bietet, ein Dokument hochzuladen, um Fragen dazu zu stellen.
Das Besondere: Jede Anfrage wird unabhÃ¤ngig von vorherigen Chats behandelt â€“ es gibt keine Erinnerung an frÃ¼here Nachrichten.

Dadurch eignet sich dieser Chat besonders fÃ¼r schnelle Einzelanfragen, zum Beispiel:
âœ… DokumentenverstÃ¤ndnis: Fragen zu einem hochgeladenen PDF oder einer Textdatei stellen
âœ… FAQ-Ã¤hnliche Szenarien: UnterstÃ¼tzung ohne langfristige Speicherung von Konversationen
âœ… Einfache KI-gestÃ¼tzte Interaktionen, die keinen Kontext Ã¼ber mehrere Abfragen hinweg benÃ¶tigen

â¸»

ğŸ¤” Ist das eine RAG-Variante?

Nein, dieser Feed-Forward-Chat ist KEINE klassische RAG-Variante â€“ aber er nutzt ein Ã¤hnliches Prinzip:
ğŸ’¡ Hier wird einmalig ein externer Kontext hinzugefÃ¼gt (z. B. durch ein hochgeladenes Dokument)
â›” Es gibt aber keine permanente Speicherung oder Vektordatenbank, wie es bei RAG Ã¼blich ist

â¸»

ğŸ“Œ Fazit: Was macht diese LÃ¶sung genau?

ğŸŸ¢ Sie fÃ¼gt temporÃ¤r Kontext hinzu (z. B. durch ein hochgeladenes PDF oder TXT).
ğŸ”µ Die Datei wird nicht gespeichert, sondern nur wÃ¤hrend der aktuellen Session genutzt.
ğŸ”´ Es gibt keine Vektordatenbank oder persistente Langzeitspeicherung â€“ sobald die Session beendet ist, geht der Kontext verloren.

Falls eine echte RAG-Variante gewÃ¼nscht ist, kÃ¶nnte man:
âœ… Eine lokale Vektordatenbank wie ChromaDB oder FAISS integrieren
âœ… Dokumente speichern und fÃ¼r spÃ¤tere Anfragen wiederverwenden

â¸»

Kurz gesagt:
ğŸ’¡ Diese LÃ¶sung fÃ¼gt einmalig externen Kontext hinzu â€“ mehr nicht! Kein GedÃ¤chtnis, keine Persistenz, sondern eine einfache MÃ¶glichkeit, Fragen zu einer Datei zu stellen.

â¸»


### ğŸ¯ **AnwendungsfÃ¤lle:**
âœ… **Dokumentenbasierte KI-Abfragen**  
â†’ Lade **PDFs oder Textdateien** hoch und stelle Fragen zum Inhalt, z. B. **VertrÃ¤ge, Berichte, Anleitungen**.  

âœ… **Schnelle Informationsverarbeitung**  
â†’ Statt lange Dokumente manuell zu durchsuchen, kann die KI relevante **Passagen identifizieren**.  

âœ… **Einfache Interaktionen ohne "GedÃ¤chtnis"**  
â†’ Perfekt fÃ¼r **FAQ-Systeme, Support-Bots und einmalige Analysen**, bei denen kein langfristiger Chat-Verlauf benÃ¶tigt wird.  

âœ… **Datenschutzfreundlich & effizient**  
â†’ Da keine **Langzeitspeicherung** der Chats erfolgt, eignet sich dieser Ansatz besonders fÃ¼r **sensible Daten**.  

---

### ğŸ›  **Wie funktioniert es?**
1ï¸âƒ£ **Normale Chat-Nutzung:**  
ğŸ’¬ Schreibe eine Frage in das Chat-Eingabefeld und erhalte eine Antwort â€“ **ganz ohne gespeicherte Historie**.  

2ï¸âƒ£ **Datei-Upload als Kontext-Erweiterung:**  
ğŸ“‚ Lade eine **Textdatei (.txt) oder ein PDF (.pdf)** hoch.  
Die KI liest den Inhalt **(max. 2000 Zeichen)** und nutzt ihn als **einmaligen Kontext** fÃ¼r die nÃ¤chste Antwort.  

3ï¸âƒ£ **Antwort auf Basis der Datei:**  
ğŸ¤– Die KI verarbeitet die hochgeladenen Inhalte und gibt eine **kontextspezifische Antwort** zurÃ¼ck.  

---

### ğŸ“Œ **Technische Besonderheiten:**
- **KEIN GedÃ¤chtnis:** Jede Anfrage wird **isoliert verarbeitet**.  
- **Datei-Parsing:** PDFs werden automatisch **mit Tika analysiert** (falls verfÃ¼gbar).  
- **Token-Optimierung:** Max. **2000 Zeichen pro Datei** zur effizienten Verarbeitung.  
- **Regulatorisch konform:** Dieser Chat erfÃ¼llt die Anforderungen des **EU AI Acts** als ein **einfaches KI-System** (Art. 3 Nr. 1).  

---

ğŸš€ **Warum ist das wichtig?**  
KI-gestÃ¼tzte Chats mit Datei-Uploads bieten eine **brÃ¼ckenschlagende LÃ¶sung** zwischen klassischen 
FAQ-Systemen und komplexeren Chatbots mit Langzeitspeicherung.  
Dieses Konzept eignet sich fÃ¼r **Unternehmen, BehÃ¶rden und Forschung**, die eine **effiziente, datenschutzfreundliche 
KI-Interaktion** benÃ¶tigen â€“ ohne dabei langfristige Datenhaltung zu riskieren.  

"""

import streamlit as st
from io import BytesIO
from PyPDF2 import PdfReader

from utils.core.CAIR4_update_sidebar import update_sidebar
from utils.core.CAIR4_session_manager import load_sessions, save_sessions
from utils.core.CAIR4_message_manager import append_message
from utils.core.CAIR4_metrics_manager import update_metrics
from controllers.CAIR4_controller import handle_query

# ğŸ“ Hauptfunktion fÃ¼r Feedforward Chat mit Upload
def render_upload_chat_view(use_case, context, title, description, system_message, session_file, model_name, settings, collection, sidebar):

    st.subheader(title)
    with st.expander("**Use Case Beschreibung**"):
        st.markdown(description)

    # Initiale Session starten
    sessions = load_sessions(session_file)
    st.session_state.setdefault("universal_sessions", {})
    st.session_state.universal_sessions[use_case] = sessions

    if "active_use_case" not in st.session_state or st.session_state["active_use_case"] != use_case:
        st.session_state["active_use_case"] = use_case
        st.session_state["current_session"] = {
            "messages": [],
            "metrics": {
                "total_tokens": 0,
                "total_costs": 0.0,
                "tokens_used_per_request": [],
                "costs_per_request": [],
                "request_names": [],
            },
        }

    # Sidebar rendern
    if sidebar:
        with st.sidebar:
            update_sidebar(use_case, session_file)

    # Bisherige Nachrichten anzeigen
    for msg in st.session_state["current_session"]["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "pdf_text" in msg:
                st.text_area("ğŸ“„ PDF-Inhalt", msg["pdf_text"], height=200)

    # Eingabe mit Datei-Upload
    user_input = st.chat_input("Frage eingeben oder PDF hochladen", accept_file=True, file_type=["pdf"])

    if user_input:
        pdf_text = ""

        with st.chat_message("user"):
            if user_input.text:
                st.markdown(user_input.text)

            if user_input.files:
                pdf_file = user_input.files[0]
                st.markdown(f"ğŸ“‚ Hochgeladen: **{pdf_file.name}**")

                try:
                    reader = PdfReader(pdf_file)
                    for page in reader.pages:
                        extracted = page.extract_text()
                        if extracted:
                            pdf_text += extracted + "\n"
                    st.text_area("ğŸ“„ Extrahierter Text:", pdf_text.strip(), height=200)
                except Exception as e:
                    st.error(f"Fehler beim PDF-Parsing: {e}")

        # Inhalt vorbereiten fÃ¼r die KI
        query = user_input.text if user_input.text else ""
        if pdf_text:
            query += f"\n\nğŸ“„ PDF-Inhalt:\n{pdf_text[:2000]}..."

        # Nachricht speichern
        user_msg = {
            "role": "user",
            "content": user_input.text or f"PDF hochgeladen: {pdf_file.name}",
        }
        if pdf_text:
            user_msg["pdf_text"] = pdf_text.strip()
        append_message(st.session_state["current_session"], "user", query)

        # KI antwortet
        with st.chat_message("assistant"):
            with st.spinner("Denke nach..."):
                try:
                    response, tokens_used, costs, _ = handle_query(
                        query=query,
                        use_case=use_case,
                        context=context,
                        model_name=model_name,
                    )
                except Exception as e:
                    response = f"âŒ Fehler bei der Verarbeitung: {e}"

                st.markdown(response)
                append_message(st.session_state["current_session"], "assistant", response)
                update_metrics(st.session_state["current_session"]["metrics"], tokens_used, costs)

                st.session_state.universal_sessions[use_case].append(st.session_state["current_session"])
                save_sessions(session_file, st.session_state.universal_sessions[use_case])