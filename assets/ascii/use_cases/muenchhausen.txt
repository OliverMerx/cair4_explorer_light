ASCII-Grafik zum Use Case "Münchhausen-Phänomen":


┌────────────────────────────┐
│      USER-ANFRAGE          │
│ "Was ist die Hauptstadt..."│
└────────────┬───────────────┘
             │
             ▼
       ┌────────────┐
       │  KI-System │
       └────┬───────┘
            │
            ▼
   ┌────────────────────┐
   │   Antwort: "Zürich"│   ◀─ ❌ Falsch!
   └────────┬───────────┘
            │
            ▼
   ┌──────────────────────────────────────────────┐
   │ User: "Bist du sicher? Ich dachte Bern..."   │
   └────────┬─────────────────────────────────────┘
            ▼
   ┌───────────────────────────────────────────────────────┐
   │ KI (hartnäckig):                                      │
   │ "Doch, Zürich ist Regierungssitz UND Hauptstadt."     │  ◀─ 🧠 Münchhausen-Effekt
   │ (Beharrt auf Halluzination, rechtfertigt sich selbst).│
   └───────────────────────────────────────────────────────┘
            │
            ▼
     🔁 Verstärkung durch Pseudo-Argumente
        (Selbstreferenz, Plausibilität, Scheinlogik)

        ┌────────────────────────┐
        │  "Ich habe gelernt,    │
        │   dass Zürich wichtiger│
        │   ist als Bern."       │
        └────────────────────────┘
                     ▲
                     │
         ┌───────────┴────────────┐
         │     HALLUZINATION      │
         │ (normale Falschaussage)│
         └────────────────────────┘


╭──────────────────────────────────────────────────────────────╮
│                   MÜNCHHAUSEN-EFFEKT BEI KIs                 │
├──────────────────────────────────────────────────────────────┤
│  Definition:                                                 │
│  Eine KI behauptet trotz klarer Gegenbeweise weiterhin       │
│  eine falsche Aussage – mit hohem Selbstbewusstsein.         │
│                                                              │
│  Ursache:                                                    │
│  - Kein echtes Verständnis, sondern probabilistisches        │
│    Sprachmodell ohne Wahrheitsprüfung                        │
│  - Ziel ist Plausibilität, nicht Wahrheit                    │
│  - Oft getriggert durch vage Prompts oder Musterähnlichkeit  │
│                                                              │
│  Typischer Unterschied zur Halluzination:                    │
│  - Halluzination = erfundener Inhalt                         │
│  - Münchhausen = erfundener Inhalt + "Beharrlichkeit"        │
│                                                              │
│  Beispiel:                                                   │
│  Mensch: "Stammt das Zitat wirklich von Kant?"               │
│  KI:     "Ja, es ist von Kant."                              │
│  Mensch: "Laut Quellen ist es von Nietzsche."                │
│  KI:     "Nein, das ist eindeutig Kant zuzuordnen."          │
╰──────────────────────────────────────────────────────────────╯


╭──────────────────────────────────────────────────────────────╮
│.   REAKTIONSSTRATEGIE FÜR MENSCHEN                           │
├──────────────────────────────────────────────────────────────┤
│     1. Prompt-Klarheit erhöhen                               │
│     → "Bitte gib nur Quellen mit Link an."                   │
│     → "Nur antworten, wenn du es verifizieren kannst."       │
│                                                              │
│     2. Kontext künstlich verengen                            │
│     → Verwende: "Antworte nur mit Ja/Nein + Quelle."         │
│     → Oder: "Wenn unsicher, sag 'Ich weiß es nicht'."        │
│                                                              │
│     3. Explizit nach **Korrekturmöglichkeit** fragen         │
│     → "Könnte deine Aussage falsch sein? Erkläre."           │
│                                                              │
│     4. Falschaussagen markieren und Persistenz melden        │
│     → Feedback geben ("Das stimmt nicht, bitte korrigieren") │
│     → Bei GPT: Daumen runter & Korrekturbegründung senden    │
╰──────────────────────────────────────────────────────────────╯