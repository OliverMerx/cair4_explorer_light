
ASCII-Grafik zum Use Case "Finetuning":

                   ┌────────────────────────────┐
                   │   Vortrainiertes Modell    │
                   └────────────┬───────────────┘
                                │
                                ▼
                    ┌──────────────────────┐
                    │  Finetuning-Trigger  │
                    │ (z.B. durch Button)  │
                    └────────────┬─────────┘
                                 │
              ┌──────────────────┼──────────────────┐
              ▼                                      ▼
     ┌────────────────────────┐            ┌─────────────────────────┐
     │ Gute Stützpunkte       │            │ Schlechte Stützpunkte   │
     │ (relevant & vielfältig)│            │ (einseitig / unklar)    │
     └────────────┬───────────┘            └────────────┬────────────┘
                  │                                   │
                  ▼                                   ▼
        ┌──────────────────────┐          ┌────────────────────────┐
        │ Modell lernt Muster  │          │ Modell lernt Fehler    │
        │ + generalisiert gut  │          │ (Overfitting-Risiko!)  │
        └────────────┬─────────┘          └────────────┬───────────┘
                     ▼                                 ▼
            ┌─────────────────────────┐       ┌────────────────────────┐
            │ Perfekte Feinjustierung │       │ Überanpassung (Overfit)│
            └─────────────────────────┘       └────────────────────────┘

              → Ziel: Lernbalance zwischen
                 Spezialisierung & Generalisierung

Generell:

✔ Es verfeinert ein bereits intelligentes Modell für einen präzisen Einsatzzweck.
✔ Es benötigt deutlich weniger Daten als das ursprüngliche Pretraining.
✔ Es kann Modelle an Organisationen, Domains oder spezielle Sprache anpassen.
✔ Es erhöht die Relevanz und Qualität der Antworten für spezifische Aufgaben.

⚠ Risiko: Zu starke Spezialisierung kann zur „Überanpassung“ (Overfitting) führen.


                      Pretraining Phase
         ┌────────────────────────────────────────┐
         │  Großes Sprachmodell (LLM) wird auf    │
         │  allgemeinem Textkorpus trainiert.     │
         │  Ziel: Sprachverständnis & Weltwissen. │
         └────────────────────────────────────────┘
                             │
                             ▼
                Übergabe an Finetuning-Modul
                             │
                             ▼
          ┌────────────────────────────────────────┐
          │  Auswahl einer spezifischen Aufgabe     │
          │  (z.B. Support-Bot, Juristisches LLM)   │
          └────────────────────────────────────────┘
                             │
                             ▼
        Bereitstellung von "Anchor Points" (Beispieldaten)
                             │
                             ▼
          ┌────────────────────────────────────────┐
          │  Feinjustierung des Modells auf Basis  │
          │  der Stützpunkte: Mustererkennung,     │
          │  Gewichtanpassung, Verlustfunktion     │
          └────────────────────────────────────────┘
                             │
                             ▼
                     🧠 Neues Spezialmodell
         ┌────────────────────────────────────────┐
         │  Modell ist auf Zielaufgabe optimiert. │
         │  (z.B. Finetuned für Rechnungsanalyse) │
         └────────────────────────────────────────┘